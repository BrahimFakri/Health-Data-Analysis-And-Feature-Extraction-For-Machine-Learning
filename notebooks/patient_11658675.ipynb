{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14493df",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06af37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from src.data import constants\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d6beb",
   "metadata": {},
   "source": [
    "### Read all data from local source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9ba49",
   "metadata": {},
   "source": [
    "MIMIC-IV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e5e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CORE\n",
    "df_admissions = pd.read_csv(constants.admissions, dtype={'admission_location': 'object','deathtime': 'object','edouttime': 'object','edregtime': 'object'})\n",
    "df_patients = pd.read_csv(constants.patients, dtype={'dod': 'object'})  \n",
    "df_transfers = pd.read_csv(constants.transfers, dtype={'careunit': 'object'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5e5b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## HOSP\n",
    "df_d_labitems = pd.read_csv(constants.d_labitems, dtype={'loinc_code': 'object'})\n",
    "df_d_icd_procedures = pd.read_csv(constants.d_icd_procedures, dtype={'icd_code': 'object', 'icd_version': 'object'})\n",
    "df_d_icd_diagnoses = pd.read_csv(constants.d_icd_diagnoses, dtype={'icd_code': 'object', 'icd_version': 'object'})\n",
    "df_d_hcpcs = pd.read_csv(constants.d_hcpcs, dtype={'category': 'object'})\n",
    "df_diagnoses_icd = pd.read_csv(constants.diagnoses_icd, dtype={'icd_code': 'object', 'icd_version': 'object'})\n",
    "df_drgcodes = pd.read_csv(constants.drgcodes)\n",
    "df_emar = pd.read_csv(constants.emar)\n",
    "df_emar_detail = pd.read_csv(constants.emar_detail, low_memory=False, dtype={'completion_interval': 'object','dose_due': 'object','dose_given': 'object','infusion_complete': 'object','infusion_rate_adjustment': 'object','infusion_rate_unit': 'object','new_iv_bag_hung': 'object','product_description_other': 'object','reason_for_no_barcode': 'object','restart_interval': 'object','route': 'object','side': 'object','site': 'object','continued_infusion_in_other_location': 'object','infusion_rate': 'object','non_formulary_visual_verification': 'object','prior_infusion_rate': 'object','product_amount_given': 'object', 'infusion_rate_adjustment_amount': 'object'})\n",
    "df_hcpcsevents = pd.read_csv(constants.hcpcsevents, dtype={'hcpcs_cd': 'object'})\n",
    "df_labevents = pd.read_csv(constants.labevents, dtype={'storetime': 'object', 'value': 'object', 'valueuom': 'object', 'flag': 'object', 'priority': 'object', 'comments': 'object'})\n",
    "df_microbiologyevents = pd.read_csv(constants.microbiologyevents, dtype={'comments': 'object', 'quantity': 'object'})\n",
    "df_poe = pd.read_csv(constants.poe, dtype={'discontinue_of_poe_id': 'object','discontinued_by_poe_id': 'object','order_status': 'object'})\n",
    "df_poe_detail = pd.read_csv(constants.poe_detail)\n",
    "df_prescriptions = pd.read_csv(constants.prescriptions, dtype={'form_rx': 'object','gsn': 'object'})\n",
    "df_procedures_icd = pd.read_csv(constants.procedures_icd, dtype={'icd_code': 'object', 'icd_version': 'object'})\n",
    "df_services = pd.read_csv(constants.services, dtype={'prev_service': 'object'})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b80bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ICU\n",
    "df_d_items = pd.read_csv(constants.d_items)\n",
    "df_procedureevents = pd.read_csv(constants.procedureevents, dtype={'value': 'object', 'secondaryordercategoryname': 'object', 'totalamountuom': 'object'})\n",
    "df_outputevents = pd.read_csv(constants.outputevents, dtype={'value': 'object'})\n",
    "df_inputevents = pd.read_csv(constants.inputevents, dtype={'value': 'object', 'secondaryordercategoryname': 'object', 'totalamountuom': 'object'})\n",
    "df_icustays = pd.read_csv(constants.icustays)\n",
    "df_datetimeevents = pd.read_csv(constants.datetimeevents, dtype={'value': 'object'})\n",
    "df_chartevents = pd.read_csv(constants.chartevents, low_memory=False, dtype={'value': 'object', 'valueuom': 'object'}, nrows=20000000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac728a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CXR\n",
    "df_mimic_cxr_chexpert = pd.read_csv(constants.mimic_cxr_chexpert)\n",
    "df_mimic_cxr_metadata = pd.read_csv(constants.mimic_cxr_metadata, dtype={'dicom_id': 'object'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51347898",
   "metadata": {},
   "source": [
    "### Create dataframe for patient  11658675"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12daf98",
   "metadata": {},
   "source": [
    "Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf93e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admissions = df_admissions[df_admissions[\"subject_id\"]==11658675]\n",
    "df_patients = df_patients[df_patients[\"subject_id\"]==11658675]\n",
    "df_transfers = df_transfers[df_transfers[\"subject_id\"]==11658675]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da60513",
   "metadata": {},
   "source": [
    "core fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b8b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df_core_fusion = df_admissions.merge(df_patients, on=(\"subject_id\")).merge(df_transfers, on=('subject_id', 'hadm_id'))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f9b367",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>anchor_year_group</th>\n",
       "      <th>dod</th>\n",
       "      <th>transfer_id</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>careunit</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11658675</td>\n",
       "      <td>29191472</td>\n",
       "      <td>2153-11-12 22:49:00</td>\n",
       "      <td>2153-11-18 12:39:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DIRECT OBSERVATION</td>\n",
       "      <td>TRANSFER FROM SKILLED NURSING FACILITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33411288</td>\n",
       "      <td>discharge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2153-11-18 12:39:41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11658675</td>\n",
       "      <td>29191472</td>\n",
       "      <td>2153-11-12 22:49:00</td>\n",
       "      <td>2153-11-18 12:39:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DIRECT OBSERVATION</td>\n",
       "      <td>TRANSFER FROM SKILLED NURSING FACILITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39586827</td>\n",
       "      <td>ED</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>2153-11-12 18:16:00</td>\n",
       "      <td>2153-11-13 00:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11658675</td>\n",
       "      <td>29191472</td>\n",
       "      <td>2153-11-12 22:49:00</td>\n",
       "      <td>2153-11-18 12:39:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DIRECT OBSERVATION</td>\n",
       "      <td>TRANSFER FROM SKILLED NURSING FACILITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36064293</td>\n",
       "      <td>admit</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>2153-11-13 00:05:00</td>\n",
       "      <td>2153-11-18 12:39:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11658675</td>\n",
       "      <td>29031589</td>\n",
       "      <td>2155-07-12 23:41:00</td>\n",
       "      <td>2155-07-13 18:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EU OBSERVATION</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32514803</td>\n",
       "      <td>discharge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2155-07-13 18:49:30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11658675</td>\n",
       "      <td>29031589</td>\n",
       "      <td>2155-07-12 23:41:00</td>\n",
       "      <td>2155-07-13 18:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EU OBSERVATION</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39360713</td>\n",
       "      <td>ED</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>2155-07-12 16:54:00</td>\n",
       "      <td>2155-07-13 01:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>11658675</td>\n",
       "      <td>20640214</td>\n",
       "      <td>2154-04-03 18:48:00</td>\n",
       "      <td>2154-04-05 12:35:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30250820</td>\n",
       "      <td>admit</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>2154-04-03 19:35:00</td>\n",
       "      <td>2154-04-05 12:38:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>11658675</td>\n",
       "      <td>20957307</td>\n",
       "      <td>2152-09-25 01:26:00</td>\n",
       "      <td>2152-09-26 18:18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30456968</td>\n",
       "      <td>discharge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2152-09-26 18:18:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>11658675</td>\n",
       "      <td>20957307</td>\n",
       "      <td>2152-09-25 01:26:00</td>\n",
       "      <td>2152-09-26 18:18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39374507</td>\n",
       "      <td>ED</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>2152-09-24 23:40:00</td>\n",
       "      <td>2152-09-25 02:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>11658675</td>\n",
       "      <td>20957307</td>\n",
       "      <td>2152-09-25 01:26:00</td>\n",
       "      <td>2152-09-26 18:18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35438877</td>\n",
       "      <td>transfer</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>2152-09-25 10:58:31</td>\n",
       "      <td>2152-09-26 18:18:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>11658675</td>\n",
       "      <td>20957307</td>\n",
       "      <td>2152-09-25 01:26:00</td>\n",
       "      <td>2152-09-26 18:18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36585342</td>\n",
       "      <td>admit</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>2152-09-25 02:56:00</td>\n",
       "      <td>2152-09-25 10:58:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject_id   hadm_id            admittime            dischtime deathtime  \\\n",
       "0      11658675  29191472  2153-11-12 22:49:00  2153-11-18 12:39:00       NaN   \n",
       "1      11658675  29191472  2153-11-12 22:49:00  2153-11-18 12:39:00       NaN   \n",
       "2      11658675  29191472  2153-11-12 22:49:00  2153-11-18 12:39:00       NaN   \n",
       "3      11658675  29031589  2155-07-12 23:41:00  2155-07-13 18:40:00       NaN   \n",
       "4      11658675  29031589  2155-07-12 23:41:00  2155-07-13 18:40:00       NaN   \n",
       "..          ...       ...                  ...                  ...       ...   \n",
       "146    11658675  20640214  2154-04-03 18:48:00  2154-04-05 12:35:00       NaN   \n",
       "147    11658675  20957307  2152-09-25 01:26:00  2152-09-26 18:18:00       NaN   \n",
       "148    11658675  20957307  2152-09-25 01:26:00  2152-09-26 18:18:00       NaN   \n",
       "149    11658675  20957307  2152-09-25 01:26:00  2152-09-26 18:18:00       NaN   \n",
       "150    11658675  20957307  2152-09-25 01:26:00  2152-09-26 18:18:00       NaN   \n",
       "\n",
       "         admission_type                      admission_location  \\\n",
       "0    DIRECT OBSERVATION  TRANSFER FROM SKILLED NURSING FACILITY   \n",
       "1    DIRECT OBSERVATION  TRANSFER FROM SKILLED NURSING FACILITY   \n",
       "2    DIRECT OBSERVATION  TRANSFER FROM SKILLED NURSING FACILITY   \n",
       "3        EU OBSERVATION                          EMERGENCY ROOM   \n",
       "4        EU OBSERVATION                          EMERGENCY ROOM   \n",
       "..                  ...                                     ...   \n",
       "146            EW EMER.                          EMERGENCY ROOM   \n",
       "147            EW EMER.                          EMERGENCY ROOM   \n",
       "148            EW EMER.                          EMERGENCY ROOM   \n",
       "149            EW EMER.                          EMERGENCY ROOM   \n",
       "150            EW EMER.                          EMERGENCY ROOM   \n",
       "\n",
       "           discharge_location insurance language  ... gender anchor_age  \\\n",
       "0                         NaN  Medicare  ENGLISH  ...      M         66   \n",
       "1                         NaN  Medicare  ENGLISH  ...      M         66   \n",
       "2                         NaN  Medicare  ENGLISH  ...      M         66   \n",
       "3                         NaN  Medicare  ENGLISH  ...      M         66   \n",
       "4                         NaN  Medicare  ENGLISH  ...      M         66   \n",
       "..                        ...       ...      ...  ...    ...        ...   \n",
       "146  SKILLED NURSING FACILITY  Medicare  ENGLISH  ...      M         66   \n",
       "147  SKILLED NURSING FACILITY  Medicare  ENGLISH  ...      M         66   \n",
       "148  SKILLED NURSING FACILITY  Medicare  ENGLISH  ...      M         66   \n",
       "149  SKILLED NURSING FACILITY  Medicare  ENGLISH  ...      M         66   \n",
       "150  SKILLED NURSING FACILITY  Medicare  ENGLISH  ...      M         66   \n",
       "\n",
       "    anchor_year anchor_year_group  dod transfer_id  eventtype  \\\n",
       "0          2152       2011 - 2013  NaN    33411288  discharge   \n",
       "1          2152       2011 - 2013  NaN    39586827         ED   \n",
       "2          2152       2011 - 2013  NaN    36064293      admit   \n",
       "3          2152       2011 - 2013  NaN    32514803  discharge   \n",
       "4          2152       2011 - 2013  NaN    39360713         ED   \n",
       "..          ...               ...  ...         ...        ...   \n",
       "146        2152       2011 - 2013  NaN    30250820      admit   \n",
       "147        2152       2011 - 2013  NaN    30456968  discharge   \n",
       "148        2152       2011 - 2013  NaN    39374507         ED   \n",
       "149        2152       2011 - 2013  NaN    35438877   transfer   \n",
       "150        2152       2011 - 2013  NaN    36585342      admit   \n",
       "\n",
       "                 careunit               intime              outtime  \n",
       "0                     NaN  2153-11-18 12:39:41                  NaN  \n",
       "1    Emergency Department  2153-11-12 18:16:00  2153-11-13 00:05:00  \n",
       "2                Medicine  2153-11-13 00:05:00  2153-11-18 12:39:41  \n",
       "3                     NaN  2155-07-13 18:49:30                  NaN  \n",
       "4    Emergency Department  2155-07-12 16:54:00  2155-07-13 01:59:00  \n",
       "..                    ...                  ...                  ...  \n",
       "146              Medicine  2154-04-03 19:35:00  2154-04-05 12:38:57  \n",
       "147                   NaN  2152-09-26 18:18:50                  NaN  \n",
       "148  Emergency Department  2152-09-24 23:40:00  2152-09-25 02:56:00  \n",
       "149              Medicine  2152-09-25 10:58:31  2152-09-26 18:18:50  \n",
       "150              Medicine  2152-09-25 02:56:00  2152-09-25 10:58:31  \n",
       "\n",
       "[151 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_core_fusion\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7904e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## HOSP\n",
    "#df_d_labitems\n",
    "#df_d_icd_procedures\n",
    "#df_d_icd_diagnoses\n",
    "#df_d_hcpcs \n",
    "df_diagnoses_icd = df_diagnoses_icd[df_diagnoses_icd[\"subject_id\"]==11658675]\n",
    "df_drgcodes = df_drgcodes[df_drgcodes[\"subject_id\"]==11658675]\n",
    "df_emar = df_emar[df_emar[\"subject_id\"]==11658675]\n",
    "df_emar_detail = df_emar_detail[df_emar_detail[\"subject_id\"]==11658675]\n",
    "df_hcpcsevents = df_hcpcsevents[df_hcpcsevents[\"subject_id\"]==11658675]\n",
    "df_labevents = df_labevents[df_labevents[\"subject_id\"]==11658675]\n",
    "df_microbiologyevents = df_microbiologyevents[df_microbiologyevents[\"subject_id\"]==11658675]\n",
    "df_poe = df_poe[df_poe[\"subject_id\"]==11658675]\n",
    "df_poe_detail = df_poe_detail[df_poe_detail[\"subject_id\"]==11658675]\n",
    "df_prescriptions = df_prescriptions[df_prescriptions[\"subject_id\"]==11658675]\n",
    "df_procedures_icd = df_procedures_icd[df_procedures_icd[\"subject_id\"]==11658675]\n",
    "df_services = df_services[df_services[\"subject_id\"]==11658675]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90974c",
   "metadata": {},
   "source": [
    "hosp fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cf0de52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8033/1433634316.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'pharmacy_id_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_hosp_fusion = df_diagnoses_icd.merge(df_drgcodes, on=('subject_id', 'hadm_id'))\\\n",
      "/tmp/ipykernel_8033/1433634316.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'seq_num_x', 'chartdate_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_hosp_fusion = df_diagnoses_icd.merge(df_drgcodes, on=('subject_id', 'hadm_id'))\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\".merge(df_emar_detail, on=('subject_id', 'hadm_id')).merge(df_hcpcsevents, on=('subject_id', 'hadm_id')).merge(df_labevents, on=('subject_id', 'hadm_id')).merge(df_microbiologyevents, on=('subject_id', 'hadm_id')).merge(df_poe, on=('subject_id', 'hadm_id')).merge(df_poe_detail, on=('subject_id', 'hadm_id')).merge(df_prescriptions, on=('subject_id', 'hadm_id')).merge(df_procedures_icd, on=('subject_id', 'hadm_id')).merge(df_services, on=('subject_id', 'hadm_id'))\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_hosp_fusion = df_diagnoses_icd.merge(df_drgcodes, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_emar, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_emar_detail, on=('subject_id'))\\\n",
    ".merge(df_hcpcsevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_emar_detail, on=('subject_id'))\\\n",
    ".merge(df_hcpcsevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_labevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_microbiologyevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_poe, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_poe_detail, on=('subject_id'))\\\n",
    ".merge(df_prescriptions, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_procedures_icd, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_services, on=('subject_id', 'hadm_id'))\n",
    "\n",
    "\"\"\"\\\n",
    "\"\"\"\n",
    ".merge(df_emar_detail, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_hcpcsevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_labevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_microbiologyevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_poe, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_poe_detail, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_prescriptions, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_procedures_icd, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_services, on=('subject_id', 'hadm_id'))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4e4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20e57263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seq_num_x', 'icd_code_x', 'icd_version_x', 'drg_type', 'drg_code',\n",
       "       'description', 'drg_severity', 'drg_mortality', 'emar_id_x',\n",
       "       'emar_seq_x',\n",
       "       ...\n",
       "       'route', 'seq_num_y', 'chartdate_y', 'icd_code_y', 'icd_version_y',\n",
       "       'subject_id', 'hadm_id', 'transfertime', 'prev_service',\n",
       "       'curr_service'],\n",
       "      dtype='object', length=161)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_hosp_fusion.columns\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df03023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_num_x</th>\n",
       "      <th>icd_code_x</th>\n",
       "      <th>icd_version_x</th>\n",
       "      <th>drg_type</th>\n",
       "      <th>drg_code</th>\n",
       "      <th>description</th>\n",
       "      <th>drg_severity</th>\n",
       "      <th>drg_mortality</th>\n",
       "      <th>emar_id_x</th>\n",
       "      <th>emar_seq_x</th>\n",
       "      <th>...</th>\n",
       "      <th>route</th>\n",
       "      <th>seq_num_y</th>\n",
       "      <th>chartdate_y</th>\n",
       "      <th>icd_code_y</th>\n",
       "      <th>icd_version_y</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>transfertime</th>\n",
       "      <th>prev_service</th>\n",
       "      <th>curr_service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [seq_num_x, icd_code_x, icd_version_x, drg_type, drg_code, description, drg_severity, drg_mortality, emar_id_x, emar_seq_x, poe_id_x, pharmacy_id_x, charttime_x, medication, event_txt, scheduletime, storetime_x, emar_id_y, emar_seq_y, parent_field_ordinal_x, administration_type_x, pharmacy_id_y, barcode_type_x, reason_for_no_barcode_x, complete_dose_not_given_x, dose_due_x, dose_due_unit_x, dose_given_x, dose_given_unit_x, will_remainder_of_dose_be_given_x, product_amount_given_x, product_unit_x, product_code_x, product_description_x, product_description_other_x, prior_infusion_rate_x, infusion_rate_x, infusion_rate_adjustment_x, infusion_rate_adjustment_amount_x, infusion_rate_unit_x, route_x, infusion_complete_x, completion_interval_x, new_iv_bag_hung_x, continued_infusion_in_other_location_x, restart_interval_x, side_x, site_x, non_formulary_visual_verification_x, chartdate_x, hcpcs_cd_x, seq_num_y, short_description_x, emar_id, emar_seq, parent_field_ordinal_y, administration_type_y, pharmacy_id_x, barcode_type_y, reason_for_no_barcode_y, complete_dose_not_given_y, dose_due_y, dose_due_unit_y, dose_given_y, dose_given_unit_y, will_remainder_of_dose_be_given_y, product_amount_given_y, product_unit_y, product_code_y, product_description_y, product_description_other_y, prior_infusion_rate_y, infusion_rate_y, infusion_rate_adjustment_y, infusion_rate_adjustment_amount_y, infusion_rate_unit_y, route_y, infusion_complete_y, completion_interval_y, new_iv_bag_hung_y, continued_infusion_in_other_location_y, restart_interval_y, side_y, site_y, non_formulary_visual_verification_y, chartdate_y, hcpcs_cd_y, seq_num_x, short_description_y, labevent_id, specimen_id, itemid, charttime_y, storetime_y, value, valuenum, valueuom, ref_range_lower, ref_range_upper, flag, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 161 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_hosp_fusion\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10670a0",
   "metadata": {},
   "source": [
    "ICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95209256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this is a label table, doesnt cntaint subject ids\n",
    "#with open(constants.d_items) as f:\n",
    "#        cols = next(f).strip().split(',')\n",
    "#        S = [\"11658675\"]\n",
    "#        df_d_items = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.procedureevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = [\"11658675\"]\n",
    "        df_procedureevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.outputevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = [\"11658675\"]\n",
    "        df_outputevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.inputevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = [\"11658675\"]\n",
    "        df_inputevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.icustays) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = [\"11658675\"]\n",
    "        df_icustays = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.datetimeevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = [\"11658675\"]\n",
    "        df_datetimeevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964a28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42609af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68533d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chartevents = pd.read_csv(constants.chartevents, dtype={'value': 'object', 'valueuom': 'object'}, nrows=20000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e768fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chartevents[df_chartevents[\"subject_id\"] == 11658675]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f19966",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_chartevents = df_chartevents[df_chartevents[\"subject_id\"] == 11658675]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chartevents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a6abf",
   "metadata": {},
   "source": [
    "icu fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66afe022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedureevents.shape,df_outputevents.shape , df_inputevents.shape, df_icustays.shape, df_datetimeevents.shape, df_chartevents.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef66d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chartevents.dtypes, df_inputevents.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chartevents.merge(df_inputevents, on=('subject_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea88f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icu_fusion = df_procedureevents.merge(df_outputevents, on=('subject_id'))\\\n",
    ".merge(df_inputevents, on=('subject_id'))\\\n",
    ".merge(df_icustays, on=('subject_id'))\\\n",
    ".merge(df_datetimeevents, on=('subject_id'))\\\n",
    ".merge(df_chartevents, on=('subject_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43177e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icu_fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234272da",
   "metadata": {},
   "source": [
    "HOSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(constants.d_labitems) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_d_labitems = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.d_hcpcs) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_d_hcpcs = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.hcpcsevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_hcpcsevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125bb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = pd.read_csv(constants.labevents, dtype={'storetime': 'object', 'value': 'object', 'valueuom': 'object', 'flag': 'object', 'priority': 'object', 'comments': 'object'}, nrows=10000000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents[df_labevents[\"subject_id\"].isin(constants.cohort)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e18968",
   "metadata": {},
   "source": [
    "hosp fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp_fusion = d_labitems.merge(d_hcpcs, on=(\"subject_id\"))\\\n",
    ".merge(hcpcsevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_labevents, on=('subject_id', 'hadm_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5760061",
   "metadata": {},
   "source": [
    "MIMIC-CXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52abcde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(constants.mimic_cxr_chexpert) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_mimic_cxr_chexpert = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.mimic_cxr_metadata) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_mimic_cxr_metadata = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[1] in S], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa114f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mimic_cxr_chexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64947b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_cxr_chexpert[mimic_cxr_chexpert[\"subject_id\"].isin(constants.cohort)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7aa205",
   "metadata": {},
   "source": [
    "CXR dataset fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cxr_fusion = df_mimic_cxr_chexpert.merge(df_mimic_cxr_metadata, on= ('subject_id', 'study_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cxr_fusion.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c734af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c356aa67",
   "metadata": {},
   "source": [
    "#### Core_Hosp_ICU_CXR Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce090ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion = df_core_fusion.merge(df_icu_fusion, on=(\"subject_id\"))\\\n",
    ".merge(df_hosp_fusion, on=(\"subject_id\")).merge(df_cxr_fusion, on=(\"subject_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf06ad",
   "metadata": {},
   "source": [
    "Demographics categorical features creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_embeddings = ['anchor_age', 'gender', 'ethnicity', 'marital_status', 'language', 'insurance']\n",
    "\n",
    "for i in range (len(demo_embeddings)):\n",
    "      \n",
    "    df_core_icu_hosp_cxr_fusion['de_'+str(i)] = df_core_icu_hosp_cxr_fusion[demo_embeddings[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c3cd1",
   "metadata": {},
   "source": [
    "Demographics categorical features encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec23fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "          df_core_icu_hosp_cxr_fusion['de_'+str(i+1)] = le.fit_transform(df_core_icu_hosp_cxr_fusion['de_'+str(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bad745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion[\"de_5\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion = df_core_icu_hosp_cxr_fusion.drop(['anchor_age', 'gender', 'ethnicity', 'marital_status', 'language', 'insurance'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion['death_status'] = np.where(df_core_icu_hosp_cxr_fusion['discharge_location'] == 'DIED' ,1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion = df_core_icu_hosp_cxr_fusion.drop(['discharge_location'], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d673fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32702f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_cxr_fusion = df_core_icu_cxr_fusion.loc[: , ['subject_id', 'hadm_id','stay_id',  'admittime','de_0', 'de_1', 'de_2',\n",
    "       'de_3', 'de_4', 'de_5', 'death_status', 'study_id', 'Atelectasis', 'Cardiomegaly', 'Consolidation',\n",
    "       'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion',\n",
    "       'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other',\n",
    "       'Pneumonia', 'Pneumothorax', 'Support Devices', 'dicom_id',\n",
    "       'PerformedProcedureStepDescription', 'ViewPosition', 'Rows', 'Columns',\n",
    "       'StudyDate', 'StudyTime', 'ProcedureCodeSequence_CodeMeaning',\n",
    "       'ViewCodeSequence_CodeMeaning',\n",
    "       'PatientOrientationCodeSequence_CodeMeaning', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e62dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_core_icu_hosp_cxr_fusion['subject_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa111091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6678f",
   "metadata": {},
   "source": [
    "# Times series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0888fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MASTER DICTIONARY OF MIMIC IV EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a71558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dictionary for chartevents, labevents and HCPCS\n",
    "df_patientevents_categorylabels_dict = pd.DataFrame(columns = ['eventtype', 'category', 'label'])\n",
    "\n",
    " \n",
    "# Load dictionaries\n",
    "df_d_items = pd.read_csv(constants.d_items)\n",
    "\n",
    "# Get Chartevent items with labels & category\n",
    "df = df_d_items\n",
    "for category_idx, category in enumerate(sorted((df.category.astype(str).unique()))):\n",
    "    #print(category)\n",
    "    category_list = df[df['category']==category]\n",
    "    for item_idx, item in enumerate(sorted(category_list.label.astype(str).unique())):\n",
    "        df_patientevents_categorylabels_dict = df_patientevents_categorylabels_dict.append({'eventtype': 'chart', 'category': category, 'label': item}, ignore_index=True)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8dde67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chartevent_tsfresh_timeseries_embeddings(dt_patient, df_patientevents_categorylabels_dict, verbose=0):\n",
    "    # Inputs:\n",
    "    #   dt_patient -> Timebound Patient ICU stay structure\n",
    "    #   df_patientevents_categorylabels_dict -> MIMIC IV Event dictionary\n",
    "    #   verbose -> Flag to print generated outputs (0,1,2)\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   evs_features -> TSfresh generated chart event features for each timeseries\n",
    "    \n",
    "    # %% EXAMPLE OF USE\n",
    "    # evs_features = extract_chartevent_tsfresh_timeseries_embeddings(dt_patient, df_patientevents_categorylabels_dict, event_type, verbose=1)\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Prep features of empty timeseries features from TSFresh in the context of clinical data\n",
    "    fc_parameters = {\"length\": None,\n",
    "                    \"absolute_sum_of_changes\": None, \n",
    "                    \"maximum\": None, \n",
    "                    \"mean\": None,\n",
    "                    \"mean_abs_change\": None,\n",
    "                    \"mean_change\": None,\n",
    "                    \"median\": None,\n",
    "                    \"minimum\": None,\n",
    "                    \"standard_deviation\": None,\n",
    "                    \"variance\": None,\n",
    "                    \"large_standard_deviation\": [{\"r\": r * 0.2} for r in range(1, 5)],\n",
    "                     \n",
    "                     # Comment by Yu: don't think we need the 1 for quntile?\n",
    "                    \"quantile\": [{\"q\": q} for q in [.25, .5, .75, 1]],\n",
    "                    \"linear_trend\": [{\"attr\": \"pvalue\"}, {\"attr\": \"rvalue\"}, {\"attr\": \"intercept\"},{\"attr\": \"slope\"}, {\"attr\": \"stderr\"}]}\n",
    "  \n",
    "    x_hr =[0]\n",
    "    y_hr = np.arange(len(x_hr))\n",
    "  \n",
    "    # Extract Features with TSFresh\n",
    "    timeseries = pd.DataFrame({'id': np.zeros_like(y_hr), 'valnum': y_hr, 'time': x_hr}, columns=['id', 'valnum', 'time'])\n",
    "    features_empty_timeseries = extract_features(timeseries, column_id=\"id\", column_sort=\"time\", disable_progressbar=True, default_fc_parameters=fc_parameters)\n",
    "    \n",
    "    \n",
    "    #Get patient events by event type\n",
    "    evs = dt_patient.chartevents\n",
    "    \n",
    "    #List all types of chart events (Charts, Labs and signals)\n",
    "    for eventtype_idx, eventtype in enumerate(sorted((df_patientevents_categorylabels_dict.eventtype.unique()))):\n",
    "        if verbose >= 3: print('* ' + eventtype)\n",
    "        event_list = df_patientevents_categorylabels_dict[df_patientevents_categorylabels_dict['eventtype']==eventtype]\n",
    "        for category_idx, category in enumerate(sorted((df_patientevents_categorylabels_dict.category.unique()))):\n",
    "            if verbose >= 3: print('-> ' + category)\n",
    "            category_list = df_patientevents_categorylabels_dict[df_patientevents_categorylabels_dict['category']==category]\n",
    "            for item_idx, item in enumerate(sorted(category_list.label.unique())):\n",
    "                if verbose >= 3: print('---> ' + item) \n",
    "                \n",
    "                # POPULATE FEATURE SPACE FOR PATIENT\n",
    "                item_chart = evs[evs['label']==item]\n",
    "                empty_timeseries = False\n",
    "                # Set x equal to the times\n",
    "                x_hr = item_chart.deltacharttime[item_chart.label==item]\n",
    "                if len(x_hr)==0: \n",
    "                    x_hr =[0]\n",
    "                    empty_timeseries = True\n",
    "                    \n",
    "                y_hr = item_chart.valuenum[item_chart.label==item]\n",
    "                y_hr = y_hr[~(np.isnan(y_hr))]\n",
    "                x_hr = x_hr[0:len(y_hr)]\n",
    "                if y_hr.empty: \n",
    "                    y_hr = np.arange(len(x_hr))\n",
    "                    extracted_features = features_empty_timeseries\n",
    "                else:                    \n",
    "                    # Extract Features with TSFresh\n",
    "                    timeseries = pd.DataFrame({'id': np.zeros_like(y_hr), 'valnum': y_hr, 'time': x_hr}, columns=['id', 'valnum', 'time'])\n",
    "                    extracted_features = impute(extract_features(timeseries, column_id=\"id\", column_sort=\"time\", disable_progressbar=disable_progressbar, default_fc_parameters = fc_parameters))\n",
    "                    \n",
    "                if (eventtype_idx ==0) & (category_idx ==0) & (item_idx == 0):\n",
    "                    evs_features = extracted_features\n",
    "                else:\n",
    "                    evs_features = evs_features.append(extracted_features) \n",
    "                    \n",
    "    # Transform extracted features from 0-1\n",
    "    transformer = QuantileTransformer().fit(evs_features)\n",
    "    norm_evs_features = transformer.transform(evs_features)\n",
    "    norm_evs_features = np.asarray(norm_evs_features)\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        # Plot feature representation\n",
    "        plt.figure(figsize = (20,5))\n",
    "        plt.imshow(X, cmap='hot', interpolation='nearest', aspect='auto')\n",
    "        plt.colorbar(label=\"Patient Timeseries Features\", orientation=\"vertical\")\n",
    "        plt.show()\n",
    "        \n",
    "    return norm_evs_features, evs_features\n",
    "\n",
    "def pivot_procedureevent(df, event_list):\n",
    "    # create a new table with additional columns with label list  \n",
    "    df1 = df[['subject_id', 'hadm_id',  'storetime']] \n",
    "    for event in event_list: \n",
    "        df1[event] = np.nan\n",
    "        #search in the label column \n",
    "        df1.loc[(df['label']==event), event] = df['value'].astype(float)  #Yu: maybe if not label use abbreviation \n",
    "    df_out = df1.dropna(axis=0, how='all', subset=event_list)\n",
    "    return df_out \n",
    "\n",
    "def pivot_chartevent(df, event_list):\n",
    "    # create a new table with additional columns with label list  \n",
    "    df1 = df[['subject_id', 'hadm_id', 'stay_id', 'charttime']] \n",
    "    for event in event_list: \n",
    "        df1[event] = np.nan\n",
    "         #search in the abbreviations column  \n",
    "        df1.loc[(df['label']==event), event] = df['valuenum'].astype(float)\n",
    "    df_out = df1.dropna(axis=0, how='all', subset=event_list)\n",
    "    return df_out \n",
    "\n",
    "\n",
    "#FUNCTION TO COMPUTE A LIST OF TIME SERIES FEATURES\n",
    "def get_ts_emb(df_pivot, event_list):\n",
    "    # Inputs:\n",
    "    #   df_pivot -> Pivoted table\n",
    "    #   event_list -> MIMIC IV Type of Event\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   df_out -> Embeddings\n",
    "    \n",
    "    # %% EXAMPLE OF USE\n",
    "    # df_out = get_ts_emb(df_pivot, event_list)\n",
    "    \n",
    "    # Initialize table\n",
    "    try:\n",
    "        df_out = df_pivot[['subject_id', 'hadm_id']].iloc[0]\n",
    "    except:\n",
    "#         print(df_pivot)\n",
    "        df_out = pd.DataFrame(columns = ['subject_id', 'hadm_id'])\n",
    "#         df_out = df_pivot[['subject_id', 'hadm_id']]\n",
    "        \n",
    "     #Adding a row of zeros to df_pivot in case there is no value\n",
    "    df_pivot = df_pivot.append(pd.Series(0, index=df_pivot.columns), ignore_index=True)\n",
    "    \n",
    "    #Compute the following features\n",
    "    for event in event_list:\n",
    "        series = df_pivot[event].dropna() #dropna rows\n",
    "        if len(series) >0: #if there is any event\n",
    "            df_out[event+'_max'] = series.max()\n",
    "            df_out[event+'_min'] = series.min()\n",
    "            df_out[event+'_mean'] = series.mean(skipna=True)\n",
    "            df_out[event+'_variance'] = series.var(skipna=True)\n",
    "            df_out[event+'_meandiff'] = series.diff().mean() #average change\n",
    "            df_out[event+'_meanabsdiff'] =series.diff().abs().mean()\n",
    "            df_out[event+'_maxdiff'] = series.diff().abs().max()\n",
    "            df_out[event+'_sumabsdiff'] =series.diff().abs().sum()\n",
    "            df_out[event+'_diff'] = series.iloc[-1]-series.iloc[0]\n",
    "            #Compute the n_peaks\n",
    "            peaks,_ = find_peaks(series) #, threshold=series.median()\n",
    "            df_out[event+'_npeaks'] = len(peaks)\n",
    "            #Compute the trend (linear slope)\n",
    "            if len(series)>1:\n",
    "                df_out[event+'_trend']= np.polyfit(np.arange(len(series)), series, 1)[0] #fit deg-1 poly\n",
    "            else:\n",
    "                 df_out[event+'_trend'] = 0\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def get_ts_embeddings(dt_patient, event_type):\n",
    "    # Inputs:\n",
    "    #   dt_patient -> Timebound Patient ICU stay structure\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   ts_emb -> TSfresh-like generated Lab event features for each timeseries\n",
    "    #\n",
    "    # %% EXAMPLE OF USE\n",
    "    # ts_emb = get_labevent_ts_embeddings(dt_patient)\n",
    "    \n",
    "    #Get chartevents\n",
    "        \n",
    "    elif(event_type == 'chart'):\n",
    "        df = dt_patient.chartevents\n",
    "        #Define chart events of interest\n",
    "        event_list = ['Heart Rate','Non Invasive Blood Pressure systolic',\n",
    "                    'Non Invasive Blood Pressure diastolic', 'Non Invasive Blood Pressure mean', \n",
    "                    'Respiratory Rate','O2 saturation pulseoxymetry', \n",
    "                    'GCS - Verbal Response', 'GCS - Eye Opening', 'GCS - Motor Response'] \n",
    "        df_pivot = pivot_chartevent(df, event_list)\n",
    "    \n",
    "    #Pivote df to record these values\n",
    "    \n",
    "    ts_emb = get_ts_emb(df_pivot, event_list)\n",
    "    try:\n",
    "        ts_emb = ts_emb.drop(['subject_id', 'hadm_id']).fillna(value=0)\n",
    "    except:\n",
    "        ts_emb = pd.Series(0, index=ts_emb.columns).drop(['subject_id', 'hadm_id']).fillna(value=0)\n",
    "\n",
    "    return ts_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cxr_embeddings_haim_id(haim_id, dt_patient, df_init):\n",
    "    # Time Series (TSFRESH-like) CHARTEVENT & LABEVENT EMBEDDINGS EXTRACTION\n",
    "    aggregated_ts_ce_embeddings = get_ts_embeddings(dt_patient, event_type = 'chart')\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    aggregated_ts_le_embeddings = get_ts_embeddings(dt_patient, event_type = 'lab')\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    aggregated_ts_pe_embeddings = get_ts_embeddings(dt_patient, event_type = 'procedure')\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "        # Create Dataframes filteed by ordered sample number for Fusion\n",
    "    df_haim_ids_fusion = pd.DataFrame([haim_id],columns=['haim_id'])\n",
    "    df_ts_ce_embeddings_fusion = pd.DataFrame(aggregated_ts_ce_embeddings.values.reshape(1,-1), columns=['ts_ce_'+str(i) for i in range(aggregated_ts_ce_embeddings.values.shape[0])])\n",
    "    df_ts_le_embeddings_fusion = pd.DataFrame(aggregated_ts_le_embeddings.values.reshape(1,-1), columns=['ts_le_'+str(i) for i in range(aggregated_ts_le_embeddings.values.shape[0])])\n",
    "    df_ts_pe_embeddings_fusion = pd.DataFrame(aggregated_ts_pe_embeddings.values.reshape(1,-1), columns=['ts_pe_'+str(i) for i in range(aggregated_ts_pe_embeddings.values.shape[0])])\n",
    "    \n",
    "    \n",
    "    # Embeddings FUSION\n",
    "    df_fusion = df_haim_ids_fusion\n",
    "    df_fusion = pd.concat([df_fusion, df_init], axis=1)\n",
    "\n",
    "    df_fusion = pd.concat([df_fusion, df_ts_ce_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_ts_le_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_ts_pe_embeddings_fusion], axis=1)\n",
    "    \n",
    "   \n",
    "    #Add targets\n",
    "    df_fusion = pd.concat([df_fusion, df_vision_targets_fusion], axis=1)\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    return df_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6c0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Let's select a single HAIM Patient from pickle files and check if it fits inclusion criteria\n",
    "haim_patient_idx = 4\n",
    "\n",
    "#Load precomputed file\n",
    "filename = f\"{haim_patient_idx:08d}\" + '.pkl'\n",
    "folder = f\"{haim_patient_idx:05d}\"[:2] + \"/\"\n",
    "patient = load_patient_object(core_mimiciv_path + 'pickle/folder' + folder + filename)\n",
    "\n",
    "# Get information of chest x-rays conducted within this patiewnt stay\n",
    "df_cxr = patient.cxr\n",
    "df_imcxr = patient.imcxr\n",
    "admittime = patient.admissions.admittime.values[0]\n",
    "dischtime = patient.admissions.dischtime.values[0]\n",
    "df_stay_cxr = df_cxr.loc[(df_cxr['charttime'] >= admittime) & (df_cxr['charttime'] <= dischtime)]\n",
    "\n",
    "if not df_stay_cxr.empty:\n",
    "    for idx, df_stay_cxr_row in df_stay_cxr.iterrows():\n",
    "        # Get stay anchor times\n",
    "        img_charttime = df_stay_cxr_row['charttime']\n",
    "        img_deltacharttime = df_stay_cxr_row['deltacharttime']\n",
    "\n",
    "        # Get time to discharge and discharge location/status\n",
    "        img_id = df_stay_cxr_row[\"dicom_id\"]\n",
    "        img_length_of_stay = date_diff_hrs(dischtime, img_charttime)\n",
    "        discharge_location = patient.core['discharge_location'][0]\n",
    "        if discharge_location == \"DIED\": death_status = 1\n",
    "        else: death_status = 0\n",
    "            \n",
    "        # Select allowed timestamp range\n",
    "        start_hr = None\n",
    "        end_hr = img_deltacharttime\n",
    "        \n",
    "        # We need to reload it since the original object has been modified\n",
    "        patient = load_patient_object(core_mimiciv_path + 'pickle/folder' + folder + filename)\n",
    "        dt_patient = get_timebound_patient_icustay(patient, start_hr , end_hr)\n",
    "        is_included = True\n",
    "\n",
    "        if is_included:\n",
    "            df_init = pd.DataFrame([[img_id, img_charttime, img_deltacharttime, discharge_location, img_length_of_stay, death_status]],columns=['img_id', 'img_charttime', 'img_deltacharttime', 'discharge_location', 'img_length_of_stay', 'death_status'])\n",
    "            df_fusion = process_cxr_embeddings_haim_id(haim_id, dt_patient, df_init)\n",
    "            \n",
    "            if os.path.isfile(fname):\n",
    "                df_fusion.to_csv(fname, mode='a', index=False, header=False)\n",
    "            else:\n",
    "                df_fusion.to_csv(fname, mode='w', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29faa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample of 10 patients\n",
    "\n",
    "#sample = read_csv(constants.icu_cxr_patients_sample10)\n",
    "\n",
    "#df_core_icu_cxr_fusion_sample = df_core_icu_cxr_fusion.loc[df_core_icu_cxr_fusion['subject_id'].isin(sample)]\n",
    "\n",
    "'''\n",
    "0    14811141\n",
    "1    18874374\n",
    "2    11272213\n",
    "3    13762583\n",
    "4    18087960\n",
    "5    13500443\n",
    "6    12189736\n",
    "7    14024750\n",
    "8    19136566\n",
    "9    18481208'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b8710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_core_icu_cxr_fusion_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10f0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
