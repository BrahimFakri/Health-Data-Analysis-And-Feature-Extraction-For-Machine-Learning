{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14493df",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06af37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from src.data import constants\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d6beb",
   "metadata": {},
   "source": [
    "### Read data from local source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9ba49",
   "metadata": {},
   "source": [
    "MIMIC-IV Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12daf98",
   "metadata": {},
   "source": [
    "Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0273c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(constants.admissions) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_admissions = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.patients) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_patients = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.transfers) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_transfers = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac3768",
   "metadata": {},
   "source": [
    "core fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d09b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_fusion = df_admissions.merge(df_patients, on=(\"subject_id\")).merge(df_transfers, on=('subject_id', 'hadm_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10670a0",
   "metadata": {},
   "source": [
    "ICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95209256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(constants.d_items) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_d_items = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.procedureevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_procedureevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.outputevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_outputevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.inputevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_inputevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.icustays) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_icustays = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.datetimeevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_datetimeevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f833e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f73a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chartevents = pd.read_csv(constants.chartevents, dtype={'value': 'object', 'valueuom': 'object'}, nrows=20000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b054e55b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_chartevents[df_chartevents[\"subject_id\"].isin([10003700])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287dd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chartevents[df_chartevents[\"subject_id\"].isin(constants.cohort)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f93089",
   "metadata": {},
   "source": [
    "icu fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09290d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icu_fusion = df_d_items.merge(df_procedureevents, on=(\"subject_id\"))\\\n",
    ".merge(df_outputevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_inputevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_icustays, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_datetimeevents, on=('subject_id', 'hadm_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0617e2",
   "metadata": {},
   "source": [
    "HOSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(constants.d_labitems) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_d_labitems = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.d_hcpcs) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_d_hcpcs = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.hcpcsevents) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_hcpcsevents = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = pd.read_csv(constants.labevents, dtype={'storetime': 'object', 'value': 'object', 'valueuom': 'object', 'flag': 'object', 'priority': 'object', 'comments': 'object'}, nrows=10000000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f823cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents[df_labevents[\"subject_id\"].isin(constants.cohort)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ce7b3",
   "metadata": {},
   "source": [
    "hosp fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a208c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp_fusion = d_labitems.merge(d_hcpcs, on=(\"subject_id\"))\\\n",
    ".merge(hcpcsevents, on=('subject_id', 'hadm_id'))\\\n",
    ".merge(df_labevents, on=('subject_id', 'hadm_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5760061",
   "metadata": {},
   "source": [
    "MIMIC-CXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52abcde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(constants.mimic_cxr_chexpert) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_mimic_cxr_chexpert = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)\n",
    "        \n",
    "with open(constants.mimic_cxr_metadata) as f:\n",
    "        cols = next(f).strip().split(',')\n",
    "        S = constants.cohort\n",
    "        df_mimic_cxr_metadata = pd.DataFrame([l for x in f if (l:=x.rstrip().split(','))[0] in S], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0dc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_cxr_chexpert[mimic_cxr_chexpert[\"subject_id\"].isin(constants.cohort)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7aa205",
   "metadata": {},
   "source": [
    "CXR dataset fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cxr_fusion = df_mimic_cxr_chexpert.merge(df_mimic_cxr_metadata, on= ('subject_id', 'study_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cxr_fusion.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb382696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c356aa67",
   "metadata": {},
   "source": [
    "#### Core_Hosp_ICU_CXR Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce090ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion = df_core_fusion.merge(df_icu_fusion, on=(\"subject_id\"))\\\n",
    ".merge(df_hosp_fusion, on=(\"subject_id\")).merge(df_cxr_fusion, on=(\"subject_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf06ad",
   "metadata": {},
   "source": [
    "Demographics categorical features creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_embeddings = ['anchor_age', 'gender', 'ethnicity', 'marital_status', 'language', 'insurance']\n",
    "\n",
    "for i in range (len(demo_embeddings)):\n",
    "      \n",
    "    df_core_icu_hosp_cxr_fusion['de_'+str(i)] = df_core_icu_hosp_cxr_fusion[demo_embeddings[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c3cd1",
   "metadata": {},
   "source": [
    "Demographics categorical features encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec23fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "          df_core_icu_hosp_cxr_fusion['de_'+str(i+1)] = le.fit_transform(df_core_icu_hosp_cxr_fusion['de_'+str(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bad745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion[\"de_5\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion = df_core_icu_hosp_cxr_fusion.drop(['anchor_age', 'gender', 'ethnicity', 'marital_status', 'language', 'insurance'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion['death_status'] = np.where(df_core_icu_hosp_cxr_fusion['discharge_location'] == 'DIED' ,1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion = df_core_icu_hosp_cxr_fusion.drop(['discharge_location'], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d673fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32702f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_icu_cxr_fusion = df_core_icu_cxr_fusion.loc[: , ['subject_id', 'hadm_id','stay_id',  'admittime','de_0', 'de_1', 'de_2',\n",
    "       'de_3', 'de_4', 'de_5', 'death_status', 'study_id', 'Atelectasis', 'Cardiomegaly', 'Consolidation',\n",
    "       'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion',\n",
    "       'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other',\n",
    "       'Pneumonia', 'Pneumothorax', 'Support Devices', 'dicom_id',\n",
    "       'PerformedProcedureStepDescription', 'ViewPosition', 'Rows', 'Columns',\n",
    "       'StudyDate', 'StudyTime', 'ProcedureCodeSequence_CodeMeaning',\n",
    "       'ViewCodeSequence_CodeMeaning',\n",
    "       'PatientOrientationCodeSequence_CodeMeaning', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e62dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_core_icu_hosp_cxr_fusion['subject_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa111091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_core_icu_hosp_cxr_fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f90c1c3",
   "metadata": {},
   "source": [
    "# Times series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0888fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MASTER DICTIONARY OF MIMIC IV EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298da939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dictionary for chartevents, labevents and HCPCS\n",
    "df_patientevents_categorylabels_dict = pd.DataFrame(columns = ['eventtype', 'category', 'label'])\n",
    "\n",
    " \n",
    "# Load dictionaries\n",
    "df_d_items = pd.read_csv(constants.d_items)\n",
    "\n",
    "# Get Chartevent items with labels & category\n",
    "df = df_d_items\n",
    "for category_idx, category in enumerate(sorted((df.category.astype(str).unique()))):\n",
    "    #print(category)\n",
    "    category_list = df[df['category']==category]\n",
    "    for item_idx, item in enumerate(sorted(category_list.label.astype(str).unique())):\n",
    "        df_patientevents_categorylabels_dict = df_patientevents_categorylabels_dict.append({'eventtype': 'chart', 'category': category, 'label': item}, ignore_index=True)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21cca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chartevent_tsfresh_timeseries_embeddings(dt_patient, df_patientevents_categorylabels_dict, verbose=0):\n",
    "    # Inputs:\n",
    "    #   dt_patient -> Timebound Patient ICU stay structure\n",
    "    #   df_patientevents_categorylabels_dict -> MIMIC IV Event dictionary\n",
    "    #   verbose -> Flag to print generated outputs (0,1,2)\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   evs_features -> TSfresh generated chart event features for each timeseries\n",
    "    \n",
    "    # %% EXAMPLE OF USE\n",
    "    # evs_features = extract_chartevent_tsfresh_timeseries_embeddings(dt_patient, df_patientevents_categorylabels_dict, event_type, verbose=1)\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Prep features of empty timeseries features from TSFresh in the context of clinical data\n",
    "    fc_parameters = {\"length\": None,\n",
    "                    \"absolute_sum_of_changes\": None, \n",
    "                    \"maximum\": None, \n",
    "                    \"mean\": None,\n",
    "                    \"mean_abs_change\": None,\n",
    "                    \"mean_change\": None,\n",
    "                    \"median\": None,\n",
    "                    \"minimum\": None,\n",
    "                    \"standard_deviation\": None,\n",
    "                    \"variance\": None,\n",
    "                    \"large_standard_deviation\": [{\"r\": r * 0.2} for r in range(1, 5)],\n",
    "                     \n",
    "                     # Comment by Yu: don't think we need the 1 for quntile?\n",
    "                    \"quantile\": [{\"q\": q} for q in [.25, .5, .75, 1]],\n",
    "                    \"linear_trend\": [{\"attr\": \"pvalue\"}, {\"attr\": \"rvalue\"}, {\"attr\": \"intercept\"},{\"attr\": \"slope\"}, {\"attr\": \"stderr\"}]}\n",
    "  \n",
    "    x_hr =[0]\n",
    "    y_hr = np.arange(len(x_hr))\n",
    "  \n",
    "    # Extract Features with TSFresh\n",
    "    timeseries = pd.DataFrame({'id': np.zeros_like(y_hr), 'valnum': y_hr, 'time': x_hr}, columns=['id', 'valnum', 'time'])\n",
    "    features_empty_timeseries = extract_features(timeseries, column_id=\"id\", column_sort=\"time\", disable_progressbar=True, default_fc_parameters=fc_parameters)\n",
    "    \n",
    "    \n",
    "    #Get patient events by event type\n",
    "    evs = dt_patient.chartevents\n",
    "    \n",
    "    #List all types of chart events (Charts, Labs and signals)\n",
    "    for eventtype_idx, eventtype in enumerate(sorted((df_patientevents_categorylabels_dict.eventtype.unique()))):\n",
    "        if verbose >= 3: print('* ' + eventtype)\n",
    "        event_list = df_patientevents_categorylabels_dict[df_patientevents_categorylabels_dict['eventtype']==eventtype]\n",
    "        for category_idx, category in enumerate(sorted((df_patientevents_categorylabels_dict.category.unique()))):\n",
    "            if verbose >= 3: print('-> ' + category)\n",
    "            category_list = df_patientevents_categorylabels_dict[df_patientevents_categorylabels_dict['category']==category]\n",
    "            for item_idx, item in enumerate(sorted(category_list.label.unique())):\n",
    "                if verbose >= 3: print('---> ' + item) \n",
    "                \n",
    "                # POPULATE FEATURE SPACE FOR PATIENT\n",
    "                item_chart = evs[evs['label']==item]\n",
    "                empty_timeseries = False\n",
    "                # Set x equal to the times\n",
    "                x_hr = item_chart.deltacharttime[item_chart.label==item]\n",
    "                if len(x_hr)==0: \n",
    "                    x_hr =[0]\n",
    "                    empty_timeseries = True\n",
    "                    \n",
    "                y_hr = item_chart.valuenum[item_chart.label==item]\n",
    "                y_hr = y_hr[~(np.isnan(y_hr))]\n",
    "                x_hr = x_hr[0:len(y_hr)]\n",
    "                if y_hr.empty: \n",
    "                    y_hr = np.arange(len(x_hr))\n",
    "                    extracted_features = features_empty_timeseries\n",
    "                else:                    \n",
    "                    # Extract Features with TSFresh\n",
    "                    timeseries = pd.DataFrame({'id': np.zeros_like(y_hr), 'valnum': y_hr, 'time': x_hr}, columns=['id', 'valnum', 'time'])\n",
    "                    extracted_features = impute(extract_features(timeseries, column_id=\"id\", column_sort=\"time\", disable_progressbar=disable_progressbar, default_fc_parameters = fc_parameters))\n",
    "                    \n",
    "                if (eventtype_idx ==0) & (category_idx ==0) & (item_idx == 0):\n",
    "                    evs_features = extracted_features\n",
    "                else:\n",
    "                    evs_features = evs_features.append(extracted_features) \n",
    "                    \n",
    "    # Transform extracted features from 0-1\n",
    "    transformer = QuantileTransformer().fit(evs_features)\n",
    "    norm_evs_features = transformer.transform(evs_features)\n",
    "    norm_evs_features = np.asarray(norm_evs_features)\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        # Plot feature representation\n",
    "        plt.figure(figsize = (20,5))\n",
    "        plt.imshow(X, cmap='hot', interpolation='nearest', aspect='auto')\n",
    "        plt.colorbar(label=\"Patient Timeseries Features\", orientation=\"vertical\")\n",
    "        plt.show()\n",
    "        \n",
    "    return norm_evs_features, evs_features\n",
    "\n",
    "\n",
    "def pivot_chartevent(df, event_list):\n",
    "    # create a new table with additional columns with label list  \n",
    "    df1 = df[['subject_id', 'hadm_id', 'stay_id', 'charttime']] \n",
    "    for event in event_list: \n",
    "        df1[event] = np.nan\n",
    "         #search in the abbreviations column  \n",
    "        df1.loc[(df['label']==event), event] = df['valuenum'].astype(float)\n",
    "    df_out = df1.dropna(axis=0, how='all', subset=event_list)\n",
    "    return df_out \n",
    "\n",
    "\n",
    "#FUNCTION TO COMPUTE A LIST OF TIME SERIES FEATURES\n",
    "def get_ts_emb(df_pivot, event_list):\n",
    "    # Inputs:\n",
    "    #   df_pivot -> Pivoted table\n",
    "    #   event_list -> MIMIC IV Type of Event\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   df_out -> Embeddings\n",
    "    \n",
    "    # %% EXAMPLE OF USE\n",
    "    # df_out = get_ts_emb(df_pivot, event_list)\n",
    "    \n",
    "    # Initialize table\n",
    "    try:\n",
    "        df_out = df_pivot[['subject_id', 'hadm_id']].iloc[0]\n",
    "    except:\n",
    "#         print(df_pivot)\n",
    "        df_out = pd.DataFrame(columns = ['subject_id', 'hadm_id'])\n",
    "#         df_out = df_pivot[['subject_id', 'hadm_id']]\n",
    "        \n",
    "     #Adding a row of zeros to df_pivot in case there is no value\n",
    "    df_pivot = df_pivot.append(pd.Series(0, index=df_pivot.columns), ignore_index=True)\n",
    "    \n",
    "    #Compute the following features\n",
    "    for event in event_list:\n",
    "        series = df_pivot[event].dropna() #dropna rows\n",
    "        if len(series) >0: #if there is any event\n",
    "            df_out[event+'_max'] = series.max()\n",
    "            df_out[event+'_min'] = series.min()\n",
    "            df_out[event+'_mean'] = series.mean(skipna=True)\n",
    "            df_out[event+'_variance'] = series.var(skipna=True)\n",
    "            df_out[event+'_meandiff'] = series.diff().mean() #average change\n",
    "            df_out[event+'_meanabsdiff'] =series.diff().abs().mean()\n",
    "            df_out[event+'_maxdiff'] = series.diff().abs().max()\n",
    "            df_out[event+'_sumabsdiff'] =series.diff().abs().sum()\n",
    "            df_out[event+'_diff'] = series.iloc[-1]-series.iloc[0]\n",
    "            #Compute the n_peaks\n",
    "            peaks,_ = find_peaks(series) #, threshold=series.median()\n",
    "            df_out[event+'_npeaks'] = len(peaks)\n",
    "            #Compute the trend (linear slope)\n",
    "            if len(series)>1:\n",
    "                df_out[event+'_trend']= np.polyfit(np.arange(len(series)), series, 1)[0] #fit deg-1 poly\n",
    "            else:\n",
    "                 df_out[event+'_trend'] = 0\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def get_ts_embeddings(dt_patient, event_type):\n",
    "    # Inputs:\n",
    "    #   dt_patient -> Timebound Patient ICU stay structure\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   ts_emb -> TSfresh-like generated Lab event features for each timeseries\n",
    "    #\n",
    "    # %% EXAMPLE OF USE\n",
    "    # ts_emb = get_labevent_ts_embeddings(dt_patient)\n",
    "    \n",
    "    #Get chartevents\n",
    "        \n",
    "    elif(event_type == 'chart'):\n",
    "        df = dt_patient.chartevents\n",
    "        #Define chart events of interest\n",
    "        event_list = ['Heart Rate','Non Invasive Blood Pressure systolic',\n",
    "                    'Non Invasive Blood Pressure diastolic', 'Non Invasive Blood Pressure mean', \n",
    "                    'Respiratory Rate','O2 saturation pulseoxymetry', \n",
    "                    'GCS - Verbal Response', 'GCS - Eye Opening', 'GCS - Motor Response'] \n",
    "        df_pivot = pivot_chartevent(df, event_list)\n",
    "    \n",
    "    #Pivote df to record these values\n",
    "    \n",
    "    ts_emb = get_ts_emb(df_pivot, event_list)\n",
    "    try:\n",
    "        ts_emb = ts_emb.drop(['subject_id', 'hadm_id']).fillna(value=0)\n",
    "    except:\n",
    "        ts_emb = pd.Series(0, index=ts_emb.columns).drop(['subject_id', 'hadm_id']).fillna(value=0)\n",
    "\n",
    "    return ts_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6659ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cxr_embeddings_haim_id(haim_id, dt_patient, df_init):\n",
    "    # Time Series (TSFRESH-like) CHARTEVENT & LABEVENT EMBEDDINGS EXTRACTION\n",
    "    aggregated_ts_ce_embeddings = get_ts_embeddings(dt_patient, event_type = 'chart')\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    aggregated_ts_le_embeddings = get_ts_embeddings(dt_patient, event_type = 'lab')\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    aggregated_ts_pe_embeddings = get_ts_embeddings(dt_patient, event_type = 'procedure')\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "        # Create Dataframes filteed by ordered sample number for Fusion\n",
    "    df_haim_ids_fusion = pd.DataFrame([haim_id],columns=['haim_id'])\n",
    "    df_ts_ce_embeddings_fusion = pd.DataFrame(aggregated_ts_ce_embeddings.values.reshape(1,-1), columns=['ts_ce_'+str(i) for i in range(aggregated_ts_ce_embeddings.values.shape[0])])\n",
    "    df_ts_le_embeddings_fusion = pd.DataFrame(aggregated_ts_le_embeddings.values.reshape(1,-1), columns=['ts_le_'+str(i) for i in range(aggregated_ts_le_embeddings.values.shape[0])])\n",
    "    df_ts_pe_embeddings_fusion = pd.DataFrame(aggregated_ts_pe_embeddings.values.reshape(1,-1), columns=['ts_pe_'+str(i) for i in range(aggregated_ts_pe_embeddings.values.shape[0])])\n",
    "    \n",
    "    \n",
    "    # Embeddings FUSION\n",
    "    df_fusion = df_haim_ids_fusion\n",
    "    df_fusion = pd.concat([df_fusion, df_init], axis=1)\n",
    "\n",
    "    df_fusion = pd.concat([df_fusion, df_ts_ce_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_ts_le_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_ts_pe_embeddings_fusion], axis=1)\n",
    "    \n",
    "   \n",
    "    #Add targets\n",
    "    df_fusion = pd.concat([df_fusion, df_vision_targets_fusion], axis=1)\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    return df_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cae90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Let's select a single HAIM Patient from pickle files and check if it fits inclusion criteria\n",
    "haim_patient_idx = 4\n",
    "\n",
    "#Load precomputed file\n",
    "filename = f\"{haim_patient_idx:08d}\" + '.pkl'\n",
    "folder = f\"{haim_patient_idx:05d}\"[:2] + \"/\"\n",
    "patient = load_patient_object(core_mimiciv_path + 'pickle/folder' + folder + filename)\n",
    "\n",
    "# Get information of chest x-rays conducted within this patiewnt stay\n",
    "df_cxr = patient.cxr\n",
    "df_imcxr = patient.imcxr\n",
    "admittime = patient.admissions.admittime.values[0]\n",
    "dischtime = patient.admissions.dischtime.values[0]\n",
    "df_stay_cxr = df_cxr.loc[(df_cxr['charttime'] >= admittime) & (df_cxr['charttime'] <= dischtime)]\n",
    "\n",
    "if not df_stay_cxr.empty:\n",
    "    for idx, df_stay_cxr_row in df_stay_cxr.iterrows():\n",
    "        # Get stay anchor times\n",
    "        img_charttime = df_stay_cxr_row['charttime']\n",
    "        img_deltacharttime = df_stay_cxr_row['deltacharttime']\n",
    "\n",
    "        # Get time to discharge and discharge location/status\n",
    "        img_id = df_stay_cxr_row[\"dicom_id\"]\n",
    "        img_length_of_stay = date_diff_hrs(dischtime, img_charttime)\n",
    "        discharge_location = patient.core['discharge_location'][0]\n",
    "        if discharge_location == \"DIED\": death_status = 1\n",
    "        else: death_status = 0\n",
    "            \n",
    "        # Select allowed timestamp range\n",
    "        start_hr = None\n",
    "        end_hr = img_deltacharttime\n",
    "        \n",
    "        # We need to reload it since the original object has been modified\n",
    "        patient = load_patient_object(core_mimiciv_path + 'pickle/folder' + folder + filename)\n",
    "        dt_patient = get_timebound_patient_icustay(patient, start_hr , end_hr)\n",
    "        is_included = True\n",
    "\n",
    "        if is_included:\n",
    "            df_init = pd.DataFrame([[img_id, img_charttime, img_deltacharttime, discharge_location, img_length_of_stay, death_status]],columns=['img_id', 'img_charttime', 'img_deltacharttime', 'discharge_location', 'img_length_of_stay', 'death_status'])\n",
    "            df_fusion = process_cxr_embeddings_haim_id(haim_id, dt_patient, df_init)\n",
    "            \n",
    "            if os.path.isfile(fname):\n",
    "                df_fusion.to_csv(fname, mode='a', index=False, header=False)\n",
    "            else:\n",
    "                df_fusion.to_csv(fname, mode='w', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dda5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample of 10 patients\n",
    "\n",
    "#sample = read_csv(constants.icu_cxr_patients_sample10)\n",
    "\n",
    "#df_core_icu_cxr_fusion_sample = df_core_icu_cxr_fusion.loc[df_core_icu_cxr_fusion['subject_id'].isin(sample)]\n",
    "\n",
    "'''\n",
    "0    14811141\n",
    "1    18874374\n",
    "2    11272213\n",
    "3    13762583\n",
    "4    18087960\n",
    "5    13500443\n",
    "6    12189736\n",
    "7    14024750\n",
    "8    19136566\n",
    "9    18481208'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b8710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_core_icu_cxr_fusion_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10f0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
